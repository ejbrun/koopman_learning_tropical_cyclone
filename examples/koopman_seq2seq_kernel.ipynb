{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from absl import app\n",
    "# from klearn_tcyclone.training_utils.args import FLAGS, ALL_FLAGS\n",
    "from klearn_tcyclone.training_utils.training_utils import get_default_flag_values\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "\n",
    "from klearn_tcyclone.climada.tc_tracks import TCTracks\n",
    "from klearn_tcyclone.data_utils import (\n",
    "    LinearScaler,\n",
    ")\n",
    "from klearn_tcyclone.KNF.modules.eval_metrics import RMSE_TCTracks\n",
    "from klearn_tcyclone.KNF.modules.models import Koopman\n",
    "from klearn_tcyclone.KNF.modules.train_utils import (\n",
    "    eval_epoch_koopman,\n",
    "    train_epoch_koopman,\n",
    ")\n",
    "from klearn_tcyclone.knf_data_utils import TCTrackDataset\n",
    "from klearn_tcyclone.training_utils.training_utils import set_flags\n",
    "from absl import app, flags\n",
    "\n",
    "from klearn_tcyclone.training_utils.training_utils import extend_by_default_flag_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some specific parameters and load default values for all other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_params = {\n",
    "    # \"seed\": 42,\n",
    "    \"year_range\": [1980, 1988],\n",
    "    # \"batch_size\": 16,\n",
    "    \"num_epochs\": 2,\n",
    "    \"train_output_length\": 1,\n",
    "    \"input_length\": 15\n",
    "}\n",
    "flag_params = extend_by_default_flag_values(flag_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "random.seed(flag_params[\"seed\"])  # python random generator\n",
    "np.random.seed(flag_params[\"seed\"])  # numpy random generator\n",
    "\n",
    "torch.manual_seed(flag_params[\"seed\"])\n",
    "torch.cuda.manual_seed_all(flag_params[\"seed\"])\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "feature_list = [\n",
    "    \"lon\",\n",
    "    \"lat\",\n",
    "    \"max_sustained_wind\",\n",
    "    \"radius_max_wind\",\n",
    "    \"radius_oci\",\n",
    "    \"central_pressure\",\n",
    "    \"environmental_pressure\",\n",
    "]\n",
    "\n",
    "# these are not contained as flags\n",
    "# encoder_hidden_dim = flag_params[\"hidden_dim\"]\n",
    "# decoder_hidden_dim = flag_params[\"hidden_dim\"]\n",
    "# encoder_num_layers = flag_params[\"num_layers\"]\n",
    "# decoder_num_layers = flag_params[\"num_layers\"]\n",
    "\n",
    "output_dim = flag_params[\"input_dim\"]\n",
    "num_feats = len(feature_list)\n",
    "learning_rate = flag_params[\"learning_rate\"]\n",
    "# ---------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "scaler = LinearScaler()\n",
    "eval_metric = RMSE_TCTracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1980, 1988]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_params[\"year_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_params[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-22 21:02:51,565 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /home/ecjb/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.\n",
      "2025-01-22 21:03:11,720 - climada.hazard.tc_tracks - WARNING - 49 storm events are discarded because no valid wind/pressure values have been found: 1980199N31284, 1980200N25270, 1980204N23287, 1980226N15339, 1980238N16328, ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecjb/packages/climada_python/climada/hazard/tc_tracks.py:614: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  if ibtracs_ds.dims['storm'] == 0:\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "tc_tracks = TCTracks.from_ibtracs_netcdf(\n",
    "    provider=\"usa\",\n",
    "    year_range=flag_params[\"year_range\"],\n",
    "    basin=\"NA\",\n",
    "    correct_pres=False,\n",
    ")\n",
    "\n",
    "tc_tracks_train, tc_tracks_test = train_test_split(tc_tracks.data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73,\n",
       " <xarray.Dataset> Size: 8kB\n",
       " Dimensions:                 (time: 134)\n",
       " Coordinates:\n",
       "   * time                    (time) datetime64[ns] 1kB 1986-08-13T12:00:00 ......\n",
       "     lat                     (time) float32 536B 30.1 30.46 30.8 ... 56.17 56.2\n",
       "     lon                     (time) float32 536B -84.0 -84.04 -84.0 ... 6.923 8.0\n",
       " Data variables:\n",
       "     radius_max_wind         (time) float32 536B 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "     radius_oci              (time) float32 536B 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "     max_sustained_wind      (time) float32 536B 10.0 10.0 10.0 ... 15.0 15.0\n",
       "     central_pressure        (time) float32 536B 1.009e+03 1.01e+03 ... 1.006e+03\n",
       "     environmental_pressure  (time) float64 1kB 1.01e+03 1.01e+03 ... 1.01e+03\n",
       "     time_step               (time) float64 1kB 3.0 3.0 3.0 3.0 ... 3.0 3.0 3.0\n",
       "     basin                   (time) <U2 1kB 'NA' 'NA' 'NA' ... 'NA' 'NA' 'NA'\n",
       " Attributes:\n",
       "     max_sustained_wind_unit:  kn\n",
       "     central_pressure_unit:    mb\n",
       "     orig_event_flag:          True\n",
       "     data_provider:            ibtracs_usa\n",
       "     category:                 1\n",
       "     name:                     CHARLEY\n",
       "     sid:                      1986226N30276\n",
       "     id_no:                    1986226030276.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tc_tracks_train), tc_tracks_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecjb/projects/koopman_learning_tropical_cyclone/klearn_tcyclone/data_utils.py:262: RuntimeWarning: divide by zero encountered in divide\n",
      "  scaling_factor = (self.target_max_vec - self.target_min_vec) / (\n",
      "/home/ecjb/projects/koopman_learning_tropical_cyclone/klearn_tcyclone/data_utils.py:266: RuntimeWarning: invalid value encountered in multiply\n",
      "  scaled_diffs_to_min_vec = scaling_factor * diffs_to_min\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set = TCTrackDataset(\n",
    "    input_length=flag_params[\"input_length\"],\n",
    "    output_length=flag_params[\"train_output_length\"],\n",
    "    tc_tracks=tc_tracks_train,\n",
    "    feature_list=feature_list,\n",
    "    mode=\"train\",\n",
    "    jumps=flag_params[\"jumps\"],\n",
    "    scaler=scaler,\n",
    "    fit=True,\n",
    ")\n",
    "valid_set = TCTrackDataset(\n",
    "    input_length=flag_params[\"input_length\"],\n",
    "    output_length=flag_params[\"train_output_length\"],\n",
    "    tc_tracks=tc_tracks_train,\n",
    "    feature_list=feature_list,\n",
    "    mode=\"valid\",\n",
    "    jumps=flag_params[\"jumps\"],\n",
    "    scaler=scaler,\n",
    "    fit=False,\n",
    ")\n",
    "test_set = TCTrackDataset(\n",
    "    input_length=flag_params[\"input_length\"],\n",
    "    output_length=flag_params[\"test_output_length\"],\n",
    "    tc_tracks=tc_tracks_test,\n",
    "    feature_list=feature_list,\n",
    "    mode=\"test\",\n",
    "    # jumps=flag_params[\"jumps\"], # jumps not used in test mode\n",
    "    scaler=scaler,\n",
    "    fit=False,\n",
    ")\n",
    "train_loader = data.DataLoader(\n",
    "    train_set, batch_size=flag_params[\"batch_size\"], shuffle=True, num_workers=1\n",
    ")\n",
    "valid_loader = data.DataLoader(\n",
    "    valid_set, batch_size=flag_params[\"batch_size\"], shuffle=True, num_workers=1\n",
    ")\n",
    "test_loader = data.DataLoader(\n",
    "    test_set, batch_size=flag_params[\"batch_size\"], shuffle=False, num_workers=1\n",
    ")\n",
    "\n",
    "if len(train_loader) == 0:\n",
    "    raise Exception(\n",
    "        \"There are likely too few data points in the test set. Try to increase year_range.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data = np.sum(\n",
    "    [\n",
    "        tc[\"time\"].shape[0] for tc in tc_tracks_train\n",
    "    ]\n",
    ")\n",
    "n_data, n_data**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([32, 15, 7]) <class 'torch.Tensor'>\n",
      "torch.Size([32, 1, 7]) <class 'torch.Tensor'>\n",
      "tensor([0.3095, 0.3048, 0.3035, 0.3017, 0.2962, 0.2890, 0.2818, 0.2747, 0.2694,\n",
      "        0.2637, 0.2553, 0.2462, 0.2387, 0.2304, 0.2198])\n",
      "tensor([0.2082])\n",
      "\n",
      "1\n",
      "torch.Size([32, 15, 7]) <class 'torch.Tensor'>\n",
      "torch.Size([32, 1, 7]) <class 'torch.Tensor'>\n",
      "tensor([0.4982, 0.5012, 0.5040, 0.5075, 0.5114, 0.5170, 0.5269, 0.5344, 0.5336,\n",
      "        0.5281, 0.5215, 0.5139, 0.5078, 0.5012, 0.4928])\n",
      "tensor([0.4838])\n",
      "\n",
      "2\n",
      "torch.Size([32, 15, 7]) <class 'torch.Tensor'>\n",
      "torch.Size([32, 1, 7]) <class 'torch.Tensor'>\n",
      "tensor([-0.2573, -0.2615, -0.2652, -0.2682, -0.2700, -0.2705, -0.2700, -0.2692,\n",
      "        -0.2684, -0.2682, -0.2684, -0.2690, -0.2700, -0.2716, -0.2732])\n",
      "tensor([-0.2741])\n",
      "\n",
      "3\n",
      "torch.Size([32, 15, 7]) <class 'torch.Tensor'>\n",
      "torch.Size([32, 1, 7]) <class 'torch.Tensor'>\n",
      "tensor([-0.0236, -0.0372, -0.0521, -0.0673, -0.0817, -0.0958, -0.1101, -0.1243,\n",
      "        -0.1387, -0.1528, -0.1660, -0.1797, -0.1952, -0.2114, -0.2272])\n",
      "tensor([-0.2431])\n",
      "\n",
      "4\n",
      "torch.Size([32, 15, 7]) <class 'torch.Tensor'>\n",
      "torch.Size([32, 1, 7]) <class 'torch.Tensor'>\n",
      "tensor([-0.1861, -0.1788, -0.1718, -0.1651, -0.1560, -0.1421, -0.1259, -0.1103,\n",
      "        -0.0942, -0.0777, -0.0610, -0.0442, -0.0277, -0.0113,  0.0040])\n",
      "tensor([0.0172])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for inps, tgts in train_loader:\n",
    "    if counter < 5:\n",
    "        print(counter)\n",
    "        print(inps.shape, type(inps))\n",
    "        print(tgts.shape, type(inps))\n",
    "        print(inps[0,:,0])\n",
    "        print(tgts[0,:,0])\n",
    "        print()\n",
    "    \n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pytorch implementation of Koopman Neural Operator.\"\"\"\n",
    "import itertools\n",
    "\n",
    "from klearn_tcyclone.KNF.modules.normalizer import RevIN\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "class KoopmanKernelSeq2Seq(nn.Module):\n",
    "    \"\"\"Koopman Neural Forecaster.\n",
    "\n",
    "    Attributes:\n",
    "    input_dim: number of steps of historical observations encoded at every step\n",
    "    input_length: input length of ts\n",
    "    output_dim: number of output features\n",
    "    num_steps: number of prediction steps every forward pass\n",
    "    encoder_hidden_dim: hidden dimension of encoder\n",
    "    decoder_hidden_dim: hidden dimension of decoder\n",
    "    encoder_num_layers: number of layers in the encoder\n",
    "    decoder_num_layers: number of layers in the decoder\n",
    "    latent_dim: dimension of finite koopman space num_feats=1: number of\n",
    "        features\n",
    "    add_global_operator: whether to use a global operator\n",
    "    add_control: whether to use a feedback module\n",
    "    control_num_layers: number of layers in the control module\n",
    "    control_hidden_dim: hidden dim in the control module\n",
    "    use_RevIN: whether to use reversible normalization\n",
    "    use_instancenorm: whether to use instance normalization on hidden states\n",
    "    regularize_rank: Whether to regularize rank of Koopman Operator.\n",
    "    num_sins: number of pairs of sine and cosine measurement functions\n",
    "    num_poly: the highest order of polynomial functions\n",
    "    num_exp: number of exponential functions\n",
    "    num_heads: Number of the head the transformer encoder\n",
    "    transformer_dim: hidden dimension of tranformer encoder\n",
    "    transformer_num_layers: number of layers in the transformer encoder\n",
    "    dropout_rate: dropout rate of MLP modules\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        input_length,\n",
    "        output_length,\n",
    "        output_dim,\n",
    "        num_steps,\n",
    "        num_nys_centers,\n",
    "        rng_seed,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_length = input_length\n",
    "        self.output_length = output_length\n",
    "        self.num_steps = num_steps\n",
    "        self.num_nys_centers = num_nys_centers\n",
    "        self.rng_seed = rng_seed\n",
    "        self.generator = torch.Generator()\n",
    "        _ = self.generator.manual_seed(self.rng_seed)        \n",
    "\n",
    "    def initialize_nystroem_kernels(self, data_set):\n",
    "        \"\"\"Initialize the nystroem kernel matrix.\n",
    "\n",
    "        Args:\n",
    "        data_set: dataset to initialize the kernel matrix\n",
    "\n",
    "        Returns:\n",
    "        nystroem_matrix: nystroem kernel matrix\n",
    "        \"\"\"\n",
    "        rand_indices = self._center_selection(data_set.shape[0], self.generator)\n",
    "\n",
    "\n",
    "\n",
    "        data_set = torch.tensor(data_set, dtype=torch.float32).to(device)\n",
    "        nystroem_matrix = torch.mm(data_set, data_set.t())\n",
    "        return nystroem_matrix\n",
    "\n",
    "    def _center_selection(self, num_pts: int, generator: torch.Generator | None = None) -> torch.Tensor:\n",
    "        if self.num_nys_centers < 1:\n",
    "            num_nys_centers = int(self.num_nys_centers * num_pts)\n",
    "        else:\n",
    "            num_nys_centers = int(self.num_nys_centers)\n",
    "\n",
    "        unif = torch.ones(num_pts)\n",
    "        rand_indices = unif.multinomial(num_nys_centers, replacement=False, generator=generator)\n",
    "\n",
    "        return rand_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = KoopmanKernelSeq2Seq(\n",
    "    1, 1, 1, 1, 1, 10, 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25, 33, 36, 67, 40, 79, 17, 70, 48, 76])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a._center_selection(100, a.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

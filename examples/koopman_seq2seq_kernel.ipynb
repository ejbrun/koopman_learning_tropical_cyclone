{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from absl import app\n",
    "# from klearn_tcyclone.training_utils.args import FLAGS, ALL_FLAGS\n",
    "from klearn_tcyclone.training_utils.training_utils import get_default_flag_values\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "\n",
    "from klearn_tcyclone.climada.tc_tracks import TCTracks\n",
    "from klearn_tcyclone.data_utils import (\n",
    "    LinearScaler,\n",
    ")\n",
    "from klearn_tcyclone.KNF.modules.eval_metrics import RMSE_TCTracks\n",
    "from klearn_tcyclone.KNF.modules.models import Koopman\n",
    "from klearn_tcyclone.KNF.modules.train_utils import (\n",
    "    eval_epoch_koopman,\n",
    "    train_epoch_koopman,\n",
    ")\n",
    "from klearn_tcyclone.knf_data_utils import TCTrackDataset\n",
    "from klearn_tcyclone.training_utils.training_utils import set_flags\n",
    "from absl import app, flags\n",
    "\n",
    "from klearn_tcyclone.training_utils.training_utils import extend_by_default_flag_values\n",
    "\n",
    "from klearn_tcyclone.koopkernel_seq2seq import KoopmanKernelSeq2Seq, RBFKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some specific parameters and load default values for all other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_params = {\n",
    "    # \"seed\": 42,\n",
    "    \"year_range\": [1980, 1988],\n",
    "    # \"batch_size\": 16,\n",
    "    \"num_epochs\": 2,\n",
    "    \"train_output_length\": 1,\n",
    "    \"input_length\": 15\n",
    "}\n",
    "flag_params = extend_by_default_flag_values(flag_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "random.seed(flag_params[\"seed\"])  # python random generator\n",
    "np.random.seed(flag_params[\"seed\"])  # numpy random generator\n",
    "\n",
    "torch.manual_seed(flag_params[\"seed\"])\n",
    "torch.cuda.manual_seed_all(flag_params[\"seed\"])\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "feature_list = [\n",
    "    \"lon\",\n",
    "    \"lat\",\n",
    "    \"max_sustained_wind\",\n",
    "    # \"radius_max_wind\",\n",
    "    # \"radius_oci\",\n",
    "    # \"central_pressure\",\n",
    "    # \"environmental_pressure\",\n",
    "]\n",
    "\n",
    "# feature_list = [\n",
    "#     \"lon\",\n",
    "#     \"lat\",\n",
    "#     \"max_sustained_wind\",\n",
    "#     \"radius_max_wind\",\n",
    "#     \"radius_oci\",\n",
    "#     \"central_pressure\",\n",
    "#     \"environmental_pressure\",\n",
    "# ]\n",
    "\n",
    "# these are not contained as flags\n",
    "# encoder_hidden_dim = flag_params[\"hidden_dim\"]\n",
    "# decoder_hidden_dim = flag_params[\"hidden_dim\"]\n",
    "# encoder_num_layers = flag_params[\"num_layers\"]\n",
    "# decoder_num_layers = flag_params[\"num_layers\"]\n",
    "\n",
    "output_dim = flag_params[\"input_dim\"]\n",
    "num_feats = len(feature_list)\n",
    "learning_rate = flag_params[\"learning_rate\"]\n",
    "# ---------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device\", device)\n",
    "\n",
    "scaler = LinearScaler()\n",
    "eval_metric = RMSE_TCTracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1980, 1988]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_params[\"year_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flag_params[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-01-24 22:45:01,145 - climada.hazard.tc_tracks - WARNING - The cached IBTrACS data set dates from 2023-06-07 23:07:38 (older than 180 days). Very likely, a more recent version is available. Consider manually removing the file /home/ecjb/climada/data/IBTrACS.ALL.v04r00.nc and re-running this function, which will download the most recent version of the IBTrACS data set from the official URL.\n",
      "2025-01-24 22:45:20,696 - climada.hazard.tc_tracks - WARNING - 49 storm events are discarded because no valid wind/pressure values have been found: 1980199N31284, 1980200N25270, 1980204N23287, 1980226N15339, 1980238N16328, ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecjb/packages/climada_python/climada/hazard/tc_tracks.py:614: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  if ibtracs_ds.dims['storm'] == 0:\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "tc_tracks = TCTracks.from_ibtracs_netcdf(\n",
    "    provider=\"usa\",\n",
    "    year_range=flag_params[\"year_range\"],\n",
    "    basin=\"NA\",\n",
    "    correct_pres=False,\n",
    ")\n",
    "\n",
    "tc_tracks_train, tc_tracks_test = train_test_split(tc_tracks.data, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73,\n",
       " <xarray.Dataset> Size: 8kB\n",
       " Dimensions:                 (time: 134)\n",
       " Coordinates:\n",
       "   * time                    (time) datetime64[ns] 1kB 1986-08-13T12:00:00 ......\n",
       "     lat                     (time) float32 536B 30.1 30.46 30.8 ... 56.17 56.2\n",
       "     lon                     (time) float32 536B -84.0 -84.04 -84.0 ... 6.923 8.0\n",
       " Data variables:\n",
       "     radius_max_wind         (time) float32 536B 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "     radius_oci              (time) float32 536B 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "     max_sustained_wind      (time) float32 536B 10.0 10.0 10.0 ... 15.0 15.0\n",
       "     central_pressure        (time) float32 536B 1.009e+03 1.01e+03 ... 1.006e+03\n",
       "     environmental_pressure  (time) float64 1kB 1.01e+03 1.01e+03 ... 1.01e+03\n",
       "     time_step               (time) float64 1kB 3.0 3.0 3.0 3.0 ... 3.0 3.0 3.0\n",
       "     basin                   (time) <U2 1kB 'NA' 'NA' 'NA' ... 'NA' 'NA' 'NA'\n",
       " Attributes:\n",
       "     max_sustained_wind_unit:  kn\n",
       "     central_pressure_unit:    mb\n",
       "     orig_event_flag:          True\n",
       "     data_provider:            ibtracs_usa\n",
       "     category:                 1\n",
       "     name:                     CHARLEY\n",
       "     sid:                      1986226N30276\n",
       "     id_no:                    1986226030276.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tc_tracks_train), tc_tracks_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set = TCTrackDataset(\n",
    "    input_length=flag_params[\"input_length\"],\n",
    "    output_length=flag_params[\"train_output_length\"],\n",
    "    tc_tracks=tc_tracks_train,\n",
    "    feature_list=feature_list,\n",
    "    mode=\"train\",\n",
    "    jumps=flag_params[\"jumps\"],\n",
    "    scaler=scaler,\n",
    "    fit=True,\n",
    ")\n",
    "valid_set = TCTrackDataset(\n",
    "    input_length=flag_params[\"input_length\"],\n",
    "    output_length=flag_params[\"train_output_length\"],\n",
    "    tc_tracks=tc_tracks_train,\n",
    "    feature_list=feature_list,\n",
    "    mode=\"valid\",\n",
    "    jumps=flag_params[\"jumps\"],\n",
    "    scaler=scaler,\n",
    "    fit=False,\n",
    ")\n",
    "test_set = TCTrackDataset(\n",
    "    input_length=flag_params[\"input_length\"],\n",
    "    output_length=flag_params[\"test_output_length\"],\n",
    "    tc_tracks=tc_tracks_test,\n",
    "    feature_list=feature_list,\n",
    "    mode=\"test\",\n",
    "    # jumps=flag_params[\"jumps\"], # jumps not used in test mode\n",
    "    scaler=scaler,\n",
    "    fit=False,\n",
    ")\n",
    "train_loader = data.DataLoader(\n",
    "    train_set, batch_size=flag_params[\"batch_size\"], shuffle=True, num_workers=1\n",
    ")\n",
    "valid_loader = data.DataLoader(\n",
    "    valid_set, batch_size=flag_params[\"batch_size\"], shuffle=True, num_workers=1\n",
    ")\n",
    "test_loader = data.DataLoader(\n",
    "    test_set, batch_size=flag_params[\"batch_size\"], shuffle=False, num_workers=1\n",
    ")\n",
    "\n",
    "if len(train_loader) == 0:\n",
    "    raise Exception(\n",
    "        \"There are likely too few data points in the test set. Try to increase year_range.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check why we have nan values!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4151, -0.3649, -0.6774],\n",
       "        [-0.4141, -0.3516, -0.6774],\n",
       "        [-0.4141, -0.3420, -0.6774],\n",
       "        [-0.4141, -0.3349, -0.6774],\n",
       "        [-0.4133, -0.3293, -0.6774],\n",
       "        [-0.4125, -0.3225, -0.6774],\n",
       "        [-0.4124, -0.3103, -0.6774],\n",
       "        [-0.4125, -0.2975, -0.6774],\n",
       "        [-0.4125, -0.2883, -0.6774],\n",
       "        [-0.4125, -0.2809, -0.6774],\n",
       "        [-0.4126, -0.2743, -0.6774],\n",
       "        [-0.4125, -0.2684, -0.6774],\n",
       "        [-0.4118, -0.2625, -0.6774],\n",
       "        [-0.4109, -0.2560, -0.6774],\n",
       "        [-0.4100, -0.2479, -0.6774]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(4250), np.int64(18062500))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_data = np.sum(\n",
    "    [\n",
    "        tc[\"time\"].shape[0] for tc in tc_tracks_train\n",
    "    ]\n",
    ")\n",
    "n_data, n_data**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([32, 15, 3]) <class 'torch.Tensor'>\n",
      "torch.Size([32, 1, 3]) <class 'torch.Tensor'>\n",
      "tensor([0.2806, 0.2795, 0.2770, 0.2747, 0.2738, 0.2732, 0.2719, 0.2700, 0.2668,\n",
      "        0.2637, 0.2618, 0.2605, 0.2589, 0.2573, 0.2559])\n",
      "tensor([0.2542])\n",
      "\n",
      "1\n",
      "torch.Size([32, 15, 3]) <class 'torch.Tensor'>\n",
      "torch.Size([32, 1, 3]) <class 'torch.Tensor'>\n",
      "tensor([-0.3539, -0.3523, -0.3500, -0.3476, -0.3460, -0.3444, -0.3421, -0.3397,\n",
      "        -0.3381, -0.3370, -0.3333, -0.3303, -0.3270, -0.3231, -0.3175])\n",
      "tensor([-0.3098])\n",
      "\n",
      "2\n",
      "torch.Size([32, 15, 3]) <class 'torch.Tensor'>\n",
      "torch.Size([32, 1, 3]) <class 'torch.Tensor'>\n",
      "tensor([-0.4600, -0.4703, -0.4806, -0.4903, -0.4996, -0.5084, -0.5170, -0.5255,\n",
      "        -0.5344, -0.5447, -0.5550, -0.5637, -0.5724, -0.5833, -0.5930])\n",
      "tensor([-0.5986])\n",
      "\n",
      "3\n",
      "torch.Size([32, 15, 3]) <class 'torch.Tensor'>\n",
      "torch.Size([32, 1, 3]) <class 'torch.Tensor'>\n",
      "tensor([0.3207, 0.3199, 0.3191, 0.3173, 0.3143, 0.3095, 0.3048, 0.3035, 0.3017,\n",
      "        0.2962, 0.2890, 0.2818, 0.2747, 0.2694, 0.2637])\n",
      "tensor([0.2553])\n",
      "\n",
      "4\n",
      "torch.Size([32, 15, 3]) <class 'torch.Tensor'>\n",
      "torch.Size([32, 1, 3]) <class 'torch.Tensor'>\n",
      "tensor([-0.0911, -0.0909, -0.0895, -0.0876, -0.0847, -0.0806, -0.0768, -0.0745,\n",
      "        -0.0736, -0.0738, -0.0752, -0.0768, -0.0800, -0.0858, -0.0926])\n",
      "tensor([-0.0983])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for inps, tgts in train_loader:\n",
    "    if counter < 5:\n",
    "        print(counter)\n",
    "        print(inps.shape, type(inps))\n",
    "        print(tgts.shape, type(inps))\n",
    "        print(inps[0,:,0])\n",
    "        print(tgts[0,:,0])\n",
    "        print()\n",
    "    \n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = RBFKernel(length_scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "koopkernelmodel = KoopmanKernelSeq2Seq(\n",
    "    kernel=rbf,\n",
    "    input_dim = 1,\n",
    "    input_length = 1,\n",
    "    output_length = 1,\n",
    "    output_dim = 1,\n",
    "    num_steps = 1,\n",
    "    num_nys_centers = 50,\n",
    "    rng_seed = 42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(koopkernelmodel.global_koopman_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2122,  0.2179, -0.1368,  ...,  0.0022, -0.0993, -0.1021],\n",
       "        [ 0.0252, -0.0875, -0.0142,  ...,  0.1951,  0.1739,  0.1662],\n",
       "        [-0.1600, -0.1150,  0.0066,  ...,  0.1789, -0.1459,  0.0782],\n",
       "        ...,\n",
       "        [ 0.2169,  0.2000,  0.1758,  ...,  0.1577, -0.1661, -0.0881],\n",
       "        [ 0.0287, -0.1941, -0.0957,  ..., -0.0567, -0.1431, -0.0213],\n",
       "        [ 0.0134,  0.1698,  0.2299,  ..., -0.0866, -0.0634, -0.1238]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "koopkernelmodel.global_koopman_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "koopkernelmodel._initialize_nystrom_data(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 15, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader_list = list(train_loader)\n",
    "inps = train_loader_list[0][0].to(device)\n",
    "inps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = koopkernelmodel.forward(inps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 15])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
